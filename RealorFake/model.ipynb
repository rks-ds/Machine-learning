{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "from collections import  Counter, defaultdict\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "stop=set(stopwords.words('english'))\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "import emoji\n",
    "from spellchecker import SpellChecker\n",
    "from textblob import TextBlob\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from nltk.stem import PorterStemmer \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import string\n",
    "from package.Clean_data import PreProcessTweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the data\n",
    "tweet_train= pd.read_csv('train.csv')\n",
    "tweet_test=pd.read_csv('test.csv')\n",
    "tweet_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Links in a tweet\n",
    "tweet_train['numoflinks']=tweet_train['text'].apply(lambda x: len(re.findall(r\"http(\\w+)\", x)))\n",
    "tweet_test['numoflinks']=tweet_test['text'].apply(lambda x: len(re.findall(r\"http(\\w+)\", x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HashTag Analysis\n",
    "def find_numhashtags(tweet):\n",
    "    hashtag_list=re.findall(r\"#(\\w+)\", tweet)\n",
    "    return len(hashtag_list)\n",
    "\n",
    "def find_hashtags(tweet):\n",
    "    #multiple hashtags case - ?\n",
    "    #hashtags in the website case\n",
    "    hashtag_list=re.findall(r\"#(\\w+)\", tweet)\n",
    "    return ', '.join([x for x in hashtag_list])\n",
    "\n",
    "def return_hashtag_keyword(tweet):\n",
    "    hashtag_list=re.findall(r\"#(\\w+)\", tweet)\n",
    "    return hashtag_list[0]\n",
    "\n",
    "tweet_train['hashtags']=tweet_train['text'].apply(lambda x: find_hashtags(x))\n",
    "tweet_train['numofhashtags']=tweet_train['text'].apply(lambda x: find_numhashtags(x))\n",
    "\n",
    "tweet_test['hashtags']=tweet_test['text'].apply(lambda x: find_hashtags(x))\n",
    "tweet_test['numofhashtags']=tweet_test['text'].apply(lambda x: find_numhashtags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr=PreProcessTweets()\n",
    "tweet_train['text']=tweet_train['text'].apply(lambda x: pr.clean_tweet(x))\n",
    "tweet_test['text']=tweet_test['text'].apply(lambda x: pr.clean_tweet(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train['keyword'].fillna(tweet_train['hashtags'].apply(lambda x: np.NaN if x=='' else x.split(',')[-1].strip()), inplace=True)\n",
    "tweet_test['keyword'].fillna(tweet_test['hashtags'].apply(lambda x: np.NaN if x=='' else x.split(',')[-1].strip()), inplace=True)\n",
    "tweet_train['keyword'].fillna('the',inplace=True)\n",
    "tweet_test['keyword'].fillna('the',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train['stem_key']=tweet_train['keyword'].apply(lambda x: pr.clean_keywords(x))\n",
    "tweet_test['stem_key']=tweet_test['keyword'].apply(lambda x: pr.clean_keywords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rks/opt/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:390: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "feature 1 - word length\n",
    "feature 2 - number of links\n",
    "feature 3 - keyword weight\n",
    "\"\"\"\n",
    "\n",
    "# feature 1 - word length\n",
    "tweet_train['avg_word_len']=tweet_train['text'].apply(lambda x: np.average([len(i) for i in x.split()]))\n",
    "tweet_test['avg_word_len']=tweet_test['text'].apply(lambda x: np.average([len(i) for i in x.split()]))\n",
    "tweet_train['avg_word_len'].fillna(0,inplace=True)\n",
    "tweet_test['avg_word_len'].fillna(0,inplace=True)\n",
    "\n",
    "# feature 2 - number of links - already done\n",
    "\n",
    "# feature 3 - keyword weight - should be normalized #\n",
    "def keyword_weight(kw,df):\n",
    "    freq1class=df[(df['stem_key']==kw)&(df['target']==1)].shape[0]\n",
    "    freq0class=df[(df['stem_key']==kw)&(df['target']==0)].shape[0]\n",
    "    if freq0class==0:\n",
    "        return freq1class\n",
    "    else:\n",
    "        return freq1class/freq0class\n",
    "tweet_train['keyword_weight']=tweet_train['stem_key'].apply(lambda x: keyword_weight(x,tweet_train))\n",
    "kw_dict=pd.Series(tweet_train.keyword_weight.values,index=tweet_train.stem_key).to_dict()\n",
    "tweet_test['keyword_weight']=tweet_test['stem_key'].apply(lambda x: kw_dict[x] if x in list(kw_dict.keys()) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]train accuracy\n",
      "0.7171942729541574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rks/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#logreg\n",
    "columns = ['avg_word_len', 'numoflinks','keyword_weight']\n",
    "train_df=tweet_train[columns]\n",
    "test_df=tweet_test[columns]\n",
    "logreg=LogisticRegression(verbose=1,random_state=0, C=5, penalty='l2')\n",
    "model=logreg.fit(train_df,tweet_train['target'])\n",
    "print(\"train accuracy\")\n",
    "train_pred=model.predict(train_df)\n",
    "print(accuracy_score(tweet_train['target'], train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model and dictionary\n",
    "import pickle\n",
    "pickle.dump(model, open(\"base_model5.pkl\", 'wb'))\n",
    "pickle.dump(kw_dict,open(\"keyword_dict.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_train['pred']=train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>numoflinks</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>numofhashtags</th>\n",
       "      <th>stem_key</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>keyword_weight</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deeds reason earthquake may allah forgive</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>earthquake</td>\n",
       "      <td>1</td>\n",
       "      <td>earthquak</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.444444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>the</td>\n",
       "      <td>NaN</td>\n",
       "      <td>residents asked shelter place notified officer...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>the</td>\n",
       "      <td>7.090909</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>people receive wildfires evacuation orders cal...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>wildfires</td>\n",
       "      <td>1</td>\n",
       "      <td>wildfir</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>wildfires</td>\n",
       "      <td>NaN</td>\n",
       "      <td>got sent photo ruby alaska smoke wildfires pou...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alaska, wildfires</td>\n",
       "      <td>2</td>\n",
       "      <td>wildfir</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     keyword location                                               text  \\\n",
       "0   1  earthquake      NaN          deeds reason earthquake may allah forgive   \n",
       "1   4         the      NaN                 forest fire near ronge sask canada   \n",
       "2   5         the      NaN  residents asked shelter place notified officer...   \n",
       "3   6   wildfires      NaN  people receive wildfires evacuation orders cal...   \n",
       "4   7   wildfires      NaN  got sent photo ruby alaska smoke wildfires pou...   \n",
       "\n",
       "   target  numoflinks           hashtags  numofhashtags   stem_key  \\\n",
       "0       1           0         earthquake              1  earthquak   \n",
       "1       1           0                                 0        the   \n",
       "2       1           0                                 0        the   \n",
       "3       1           0          wildfires              1    wildfir   \n",
       "4       1           0  Alaska, wildfires              2    wildfir   \n",
       "\n",
       "   avg_word_len  keyword_weight  pred  \n",
       "0      6.000000        3.444444     1  \n",
       "1      4.833333        1.277778     0  \n",
       "2      7.090909        1.277778     0  \n",
       "3      8.000000        8.000000     1  \n",
       "4      5.222222        8.000000     1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
